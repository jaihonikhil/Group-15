{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Processing Code For Task 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaihonikhil/Group-15/blob/Jaya/Processing_Code_For_Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuDuo-9dWovf"
      },
      "source": [
        "PREPROCESSING CODE FOR ONE XML FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHcI0HCa_c8Y",
        "outputId": "a431b224-4072-4629-dc12-3a6222294a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks0HDnMuwTl9"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/Autogenerated Annotations.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/My Drive')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyObIGVW09eT"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/Manual Annotations.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/My Drive')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n4kJ-r_4Qo8"
      },
      "source": [
        "from os import walk\n",
        "mypathTrainI=\"/content/drive/My Drive/Autogenerated Annotations/Train/input\"\n",
        "mypathTrainO=\"/content/drive/My Drive/Autogenerated Annotations/Train/output\"\n",
        "mypathDevI=\"/content/drive/My Drive/Autogenerated Annotations/Dev/input\"\n",
        "mypathDevO=\"/content/drive/My Drive/Autogenerated Annotations/Dev/output\"\n",
        "# mypathDevO=\"/content/drive/My Drive/Manual Annotations/Dev/output\""
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0T8qwY-har"
      },
      "source": [
        "import os\n",
        "files_in_directory = os.listdir(mypathDevO)#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "examples = [file for file in files_in_directory if file.endswith(\".xml\")]\n",
        "for e in range(len(examples)):\n",
        "  examples[e]=examples[e][:-4]\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pcDhTIlVvG4"
      },
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import numpy as np\n",
        "import json\n",
        "import csv \n",
        "filename=[]\n",
        "stateme=[]\n",
        "ind=[]\n",
        "captio=[]\n",
        "for example1 in examples:\n",
        "  content = []\n",
        "  with open(mypathDevO+\"/\"+example1+\".xml\", \"r\") as file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "      content = file.readlines()\n",
        "      content = \"\".join(content)\n",
        "      soup = bs(content, \"lxml\")\n",
        "  matrices=[]\n",
        "  tables = soup.find_all('table')\n",
        "  num_tables = len(tables)\n",
        "  p=0\n",
        "  \n",
        "  for t in tables:\n",
        "    p=p+1  \n",
        "    row=t.find_all('row')\n",
        "    capt=t.find('caption')\n",
        "    statements=t.find_all('statement')\n",
        "    state=[]\n",
        "    index=[]\n",
        "    for s in statements:\n",
        "      a_list = s['text'].split()\n",
        "      s['text'] = \" \".join(a_list)\n",
        "      if (s['type']=='entailed'):\n",
        "        state.append(s['text'])\n",
        "        s['type']='1'\n",
        "        index.append(s['type'])\n",
        "      elif (s['type']=='refuted'):\n",
        "        state.append(s['text'])\n",
        "        s['type']='0'\n",
        "        index.append(s['type'])\n",
        "    \n",
        "    stateme.append(state)\n",
        "    ind.append(index)\n",
        "    if (capt!=None):\n",
        "      a_list = capt['text'].split()\n",
        "      capt['text'] = \" \".join(a_list)\n",
        "      captio.append(capt['text'])\n",
        "    else:\n",
        "      captio.append(\" \")\n",
        "    cells=[]\n",
        "    for s in row:\n",
        "      table_s = s.find_all('cell')\n",
        "      cells.append(len(table_s))\n",
        "    m=max(cells)# For intrapolating hence finding maximum number of columns\n",
        "    matrix=[]\n",
        "    lex=[]\n",
        "    for r in row:\n",
        "      table_rows = r.find_all('cell')\n",
        "      j=0\n",
        "      x=0\n",
        "      s=\"\"\n",
        "      rowstring=\"\"\n",
        "      for j in range(m):\n",
        "        l=table_rows[x]\n",
        "        if(j==int(l['col'])):\n",
        "          rowstring=rowstring+l['text']+'#'\n",
        "          s=l['text']\n",
        "          if(x<len(table_rows)-1):\n",
        "            x=x+1\n",
        "        else :\n",
        "          rowstring=rowstring+s+'#'\n",
        "        j=j+1\n",
        "      rowstring=rowstring[:-1]\n",
        "      a_list = rowstring.split()\n",
        "      new_string = \" \".join(a_list)\n",
        "      lex.append(new_string)\n",
        "      matrix.append(lex)\n",
        "      lex=[]\n",
        "      s=\"\"\n",
        "      rowstring=\"\"\n",
        "    filename.append(example1+\".\"+str(p)+\".html.csv\")\n",
        "    dir=\"/content/drive/My Drive/DevOutput/\"#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "    file = open(dir+example1+\".\"+str(p)+'.html.csv', 'w', newline ='') \n",
        "    with file:     \n",
        "      write = csv.writer(file) \n",
        "      write.writerows(matrix) \n",
        "    matrices.append(matrix)\n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNwGTr4nWFHQ"
      },
      "source": [
        "#Creates File For Json Writing \n",
        "feeds=[]\n",
        "with open(\"/content/drive/My Drive/Group15Data/Devoutput.json\", \"w\") as write_file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "  for i in range(len(filename)):\n",
        "    a_list = captio[i].split()\n",
        "    new_string = \" \".join(a_list)\n",
        "    entry = {filename[i]:[stateme[i], ind[i],new_string]}\n",
        "    feeds.append(entry)\n",
        "    i=i+1\n",
        "  json.dump(feeds, write_file,indent=4)\n",
        "#Json writing ends"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbyHl7bg2ElO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}