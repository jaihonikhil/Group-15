{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Processing Code For Task 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaihonikhil/Group-15/blob/master/Processing_Code_For_Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuDuo-9dWovf"
      },
      "source": [
        "PREPROCESSING CODE FOR XML FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHcI0HCa_c8Y",
        "outputId": "5005613f-15c4-446b-b70a-3581f789fb58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks0HDnMuwTl9"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/Autogenerated Annotations.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/My Drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKDuTSLX48eQ"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/Manual Annotations v2.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/My Drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPa81eACe1T4"
      },
      "source": [
        "from os import walk\n",
        "mypathTrainI=\"/content/drive/My Drive/Manual Annotations/Train/input\"\n",
        "mypathTrainO=\"/content/drive/My Drive/Autogenerated Annotations/Train/output\"\n",
        "mypathDevI=\"/content/drive/My Drive/Manual Annotations/Dev/input\"\n",
        "mypathDevO=\"/content/drive/My Drive/Autogenerated Annotations/Dev/output\"\n",
        "# mypathDevO=\"/content/drive/My Drive/Manual Annotations/Dev/output\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0T8qwY-har"
      },
      "source": [
        "import os\n",
        "files_in_directory = os.listdir(mypathTrainO)#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "examples = [file for file in files_in_directory if file.endswith(\".xml\")]\n",
        "for e in range(len(examples)):\n",
        "  examples[e]=examples[e][:-4]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFc2WQA-8iPv",
        "outputId": "bb8ded98-d04d-46d2-b056-40e875b75fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "684"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pcDhTIlVvG4"
      },
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import numpy as np\n",
        "import json\n",
        "import csv \n",
        "filename=[]\n",
        "stateme=[]\n",
        "ind=[]\n",
        "captio=[]\n",
        "for example1 in examples:\n",
        "  content = []\n",
        "  with open(mypathTrainO+\"/\"+example1+\".xml\", \"r\") as file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "      content = file.readlines()\n",
        "      content = \"\".join(content)\n",
        "      soup = bs(content, \"lxml\")\n",
        "  matrices=[]\n",
        "  tables = soup.find_all('table')\n",
        "  num_tables = len(tables)\n",
        "  p=0\n",
        "  \n",
        "  for t in tables:\n",
        "    p=p+1  \n",
        "    row=t.find_all('row')\n",
        "    capt=t.find('caption')\n",
        "    statements=t.find_all('statement')\n",
        "    state=[]\n",
        "    index=[]\n",
        "    for s in statements:\n",
        "      a_list = s['text'].split()\n",
        "      s['text'] = \" \".join(a_list)\n",
        "      s['text']=str(s['text'])\n",
        "      s['text']=s['text'].replace(\"#\",\"\")\n",
        "      # print(s['text'])\n",
        "      if (s['type']=='entailed'):\n",
        "        state.append(s['text'])\n",
        "        s['type']=1\n",
        "        index.append(s['type'])\n",
        "      elif (s['type']=='refuted'):\n",
        "        state.append(s['text'])\n",
        "        s['type']=0\n",
        "        index.append(s['type'])\n",
        "    \n",
        "    stateme.append(state)\n",
        "    ind.append(index)\n",
        "    if (capt!=None):\n",
        "      a_list = capt['text'].split()\n",
        "      capt['text'] = \" \".join(a_list)\n",
        "      capt['text']=capt['text'].replace(\"#\",\"\")\n",
        "      captio.append(capt['text'])\n",
        "    else:\n",
        "      captio.append(\" \")\n",
        "    cells=[]\n",
        "    for s in row:\n",
        "      table_s = s.find_all('cell')\n",
        "      cells.append(len(table_s))\n",
        "    m=max(cells)# For intrapolating hence finding maximum number of columns\n",
        "    matrix=[]\n",
        "    lex=[]\n",
        "    for r in row:\n",
        "      table_rows = r.find_all('cell')\n",
        "      j=0\n",
        "      x=0\n",
        "      s=\"\"\n",
        "      rowstring=\"\"\n",
        "      for j in range(m):\n",
        "        l=table_rows[x]\n",
        "        if(j==int(l['col'])):\n",
        "          l['text']=l['text'].replace(\"#\",\"\")\n",
        "          rowstring=rowstring+l['text']+'#'\n",
        "          s=l['text']\n",
        "          if(x<len(table_rows)-1):\n",
        "            x=x+1\n",
        "        else :\n",
        "          rowstring=rowstring+s+'#'\n",
        "        j=j+1\n",
        "      rowstring=rowstring[:-1]\n",
        "      a_list = rowstring.split()\n",
        "      new_string = \" \".join(a_list)\n",
        "      lex.append(new_string)\n",
        "      matrix.append(lex)\n",
        "      lex=[]\n",
        "      s=\"\"\n",
        "      rowstring=\"\"\n",
        "    filename.append(example1+\".\"+str(p)+\"TRAO.html.csv\")\n",
        "    dir=\"/content/drive/My Drive/TrainAOutput/\"#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "    file = open(dir+example1+\".\"+str(p)+'TRAO.html.csv', 'w', newline ='') \n",
        "    with file:     \n",
        "      write = csv.writer(file) \n",
        "      write.writerows(matrix) \n",
        "    matrices.append(matrix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hppEc4rq8vL7"
      },
      "source": [
        "len(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNwGTr4nWFHQ"
      },
      "source": [
        "#Creates File For Json Writing \n",
        "feeds={}\n",
        "with open(\"/content/drive/My Drive/Group-15/TrainOutputA.json\", \"w\",encoding='utf8') as write_file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "  for i in range(len(filename)):\n",
        "    a_list = captio[i].split()\n",
        "    new_string = \" \".join(a_list)\n",
        "    entry ={filename[i]:[stateme[i], ind[i],new_string]}\n",
        "    feeds.update(entry)\n",
        "    i=i+1\n",
        "  json.dump(feeds,write_file,indent=2,ensure_ascii=False, )\n",
        "    # json.dumps(feeds)\n",
        " \n",
        "#Json writing ends"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzK73t5F89SQ"
      },
      "source": [
        "**Autogenerated**\n",
        "\n",
        "> Train Output-1589 Tables 684 files\n",
        "\n",
        "> Dev Output-164 Tables 84 files\n",
        "\n",
        "**Manual**\n",
        "\n",
        "\n",
        "> Train Output- 783  Tables 340 files\n",
        "\n",
        "\n",
        "> Dev Output-100 Tables 42 files"
      ]
    }
  ]
}